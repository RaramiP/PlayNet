{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e646ed",
   "metadata": {},
   "source": [
    "### Trying different model including ResNet, EfficientNet, etc ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae86c9",
   "metadata": {},
   "source": [
    "#### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2d3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e774361",
   "metadata": {},
   "source": [
    "#### Training ResNet on dataset :\n",
    "Because ResNet was already trained with millions of images, it already know how to detect lots of visual features. Now we are fine tuning it with the in game screenshot of our games.  \n",
    "Freezing strategy:\n",
    "\n",
    "- Freeze backbone → Train only the head first (fast, stable)\n",
    "- Unfreeze late layers → Fine-tune layer3/layer4 to adapt to game screenshots\n",
    "- Keep early layers frozen → Those generic features rarely need changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22f24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "FINAL_GENRES = [\n",
    "    'Action', 'Free To Play', 'Strategy', 'Adventure', 'Indie', 'RPG',\n",
    "    'Casual', 'Simulation', 'Racing', 'Massively Multiplayer', 'Sports', 'Other'\n",
    "]\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {DEVICE}\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "NUM_EPOCHS_FROZEN = 5      # epochs with backbone frozen\n",
    "NUM_EPOCHS_UNFROZEN = 10   # epochs with backbone unfrozen\n",
    "\n",
    "# ============================================================\n",
    "# DATASET\n",
    "# ============================================================\n",
    "\n",
    "class GameScreenshotDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['image_path'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        labels = torch.tensor(\n",
    "            row[FINAL_GENRES].values.astype(float), \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, labels\n",
    "\n",
    "# ============================================================\n",
    "# TRANSFORMS\n",
    "# ============================================================\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # predifined\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# MODEL WITH FREEZING UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def create_model(num_classes, freeze_backbone=True):\n",
    "    \"\"\"Create ResNet50 with custom classifier head.\"\"\"\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    # freezing every parameters\n",
    "    if freeze_backbone:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Replace classifier (always trainable), which mean only the backbone is freezed now\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def unfreeze_layers(model, unfreeze_from='layer3'):\n",
    "    \"\"\"\n",
    "    Gradually unfreeze layers.\n",
    "    ResNet structure: conv1 -> bn1 -> layer1 -> layer2 -> layer3 -> layer4 -> fc\n",
    "    \n",
    "    unfreeze_from options:\n",
    "        'layer4' - unfreeze only last residual block (conservative)\n",
    "        'layer3' - unfreeze last two blocks (balanced)\n",
    "        'layer2' - unfreeze more (aggressive)\n",
    "        'all'    - unfreeze everything\n",
    "    \"\"\"\n",
    "    if unfreeze_from == 'all':\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"Unfroze all layers\")\n",
    "        return\n",
    "    \n",
    "    # Define layer order\n",
    "    layer_order = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "    unfreeze_idx = layer_order.index(unfreeze_from)\n",
    "    layers_to_unfreeze = layer_order[unfreeze_idx:]\n",
    "    \n",
    "    for name, child in model.named_children():\n",
    "        if name in layers_to_unfreeze:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(f\"Unfroze {name}\")\n",
    "    \n",
    "    # fc is always unfrozen\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable vs total parameters.\"\"\"\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    return trainable, total\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, threshold=0.5):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        preds = torch.sigmoid(outputs) >= threshold\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    # Metrics\n",
    "    exact_match = (all_preds == all_labels).all(dim=1).float().mean().item()\n",
    "    \n",
    "    # Per-label precision, recall, F1\n",
    "    tp = (all_preds * all_labels).sum(dim=0).float()\n",
    "    fp = (all_preds * (1 - all_labels)).sum(dim=0).float()\n",
    "    fn = ((1 - all_preds) * all_labels).sum(dim=0).float()\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    \n",
    "    return {\n",
    "        'loss': running_loss / len(loader.dataset),\n",
    "        'exact_match': exact_match,\n",
    "        'macro_f1': f1.mean().item(),\n",
    "        'per_label_f1': dict(zip(FINAL_GENRES, f1.tolist()))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6a182",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03225f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    full_dataset = GameScreenshotDataset(\n",
    "        csv_path=\"../data/dataset.csv\",\n",
    "        img_dir=\"../data/dataset_images\",\n",
    "        transform=None\n",
    "    )\n",
    "    \n",
    "    # Train/val split (80/20)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Apply transforms\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    val_dataset.dataset.transform = val_transform\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "    \n",
    "    # Create model with frozen backbone\n",
    "    model = create_model(num_classes=len(FINAL_GENRES), freeze_backbone=True)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    trainable, total = count_parameters(model)\n",
    "    print(f\"Parameters: {trainable:,} trainable / {total:,} total\")\n",
    "    \n",
    "    # Loss with class weighting (optional)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # ========================================\n",
    "    # PHASE 1: Train only classifier head\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PHASE 1: Training classifier head (backbone frozen)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS_FROZEN):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_metrics = validate(model, val_loader, criterion)\n",
    "        \n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS_FROZEN}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_metrics['loss']:.4f}, Exact Match: {val_metrics['exact_match']:.4f}, Macro F1: {val_metrics['macro_f1']:.4f}\")\n",
    "        \n",
    "        if val_metrics['macro_f1'] > best_f1:\n",
    "            best_f1 = val_metrics['macro_f1']\n",
    "            torch.save(model.state_dict(), \"best_model_phase1.pth\")\n",
    "    \n",
    "    # ========================================\n",
    "    # PHASE 2: Unfreeze and fine-tune\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PHASE 2: Fine-tuning (unfreezing layer3 and layer4)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load best model from phase 1\n",
    "    model.load_state_dict(torch.load(\"best_model_phase1.pth\"))\n",
    "    \n",
    "    # Unfreeze later layers\n",
    "    unfreeze_layers(model, unfreeze_from='layer3')\n",
    "    \n",
    "    trainable, total = count_parameters(model)\n",
    "    print(f\"Parameters: {trainable:,} trainable / {total:,} total\")\n",
    "    \n",
    "    # Lower learning rate for fine-tuning\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.layer3.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.fc.parameters(), 'lr': 1e-4},\n",
    "    ])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS_UNFROZEN):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_metrics = validate(model, val_loader, criterion)\n",
    "        \n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS_UNFROZEN}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_metrics['loss']:.4f}, Exact Match: {val_metrics['exact_match']:.4f}, Macro F1: {val_metrics['macro_f1']:.4f}\")\n",
    "        \n",
    "        if val_metrics['macro_f1'] > best_f1:\n",
    "            best_f1 = val_metrics['macro_f1']\n",
    "            torch.save(model.state_dict(), \"best_model_final.pth\")\n",
    "            print(\"  -> New best model saved!\")\n",
    "    \n",
    "    # ========================================\n",
    "    # Final evaluation\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model.load_state_dict(torch.load(\"best_model_final.pth\"))\n",
    "    val_metrics = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f\"Best Macro F1: {val_metrics['macro_f1']:.4f}\")\n",
    "    print(f\"Per-label F1:\")\n",
    "    for genre, f1 in val_metrics['per_label_f1'].items():\n",
    "        print(f\"  {genre}: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d887ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4788, Val: 1198\n",
      "Parameters: 1,055,244 trainable / 24,563,276 total\n",
      "\n",
      "==================================================\n",
      "PHASE 1: Training classifier head (backbone frozen)\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS_FROZEN):\n\u001b[32m     50\u001b[39m     train_loss = train_epoch(model, train_loader, criterion, optimizer)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     val_metrics = \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     scheduler.step(val_metrics[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS_FROZEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/PlayNet/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 173\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(model, loader, criterion, threshold)\u001b[39m\n\u001b[32m    171\u001b[39m tp = (all_preds * all_labels).sum(dim=\u001b[32m0\u001b[39m).float()\n\u001b[32m    172\u001b[39m fp = (all_preds * (\u001b[32m1\u001b[39m - all_labels)).sum(dim=\u001b[32m0\u001b[39m).float()\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m fn = ((\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m) * all_labels).sum(dim=\u001b[32m0\u001b[39m).float()\n\u001b[32m    175\u001b[39m precision = tp / (tp + fp + \u001b[32m1e-8\u001b[39m)\n\u001b[32m    176\u001b[39m recall = tp / (tp + fn + \u001b[32m1e-8\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/PlayNet/.venv/lib/python3.14/site-packages/torch/_tensor.py:45\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(sargs):\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, sargs, *sargs, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/PlayNet/.venv/lib/python3.14/site-packages/torch/_tensor.py:1075\u001b[39m, in \u001b[36mTensor.__rsub__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1073\u001b[39m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: Union[\u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m]) -> \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_VariableFunctions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead."
     ]
    }
   ],
   "source": [
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PlayNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
